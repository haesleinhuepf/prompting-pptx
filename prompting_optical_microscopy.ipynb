{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41276d57-e826-4679-a662-0edda5c03858",
   "metadata": {},
   "source": [
    "# Auto-generating PowerPoint files with chatGPT and Dall-E\n",
    "In this notebook we will generate a Powerpoint file that guides us through the basics of research data management. The receipe, all text and images will be auto-generated using generative artificial intelligence. We will use this prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d5571e-cf4d-4123-b4a5-cfc1228f6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Explain the basics of optical microscopy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3aef2a1-15d8-490d-90ad-d89684e3c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = \"chatGPT, Dall-E and Robert Haase\"\n",
    "pptx_filename = \"microscopy.pptx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73902ba8-35d5-4c46-ba65-f0acbb8ad40c",
   "metadata": {},
   "source": [
    "To make this notebook work, make sure some libraries are installed, e.g. using pip:\n",
    "```\n",
    "pip install pillow python-pptx openai scikit-image\n",
    "```\n",
    "\n",
    "These versions were used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb818eb-cde8-4477-897d-211e017703d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.23'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pptx\n",
    "pptx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98060036-72d2-4d1a-bb84-38523a4507d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e0c50a-e5b1-49b2-8726-a353565fefcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.5.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "PIL.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f8723a-be74-467f-a98e-baca48f59414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338a5788-1c4b-4a3a-ad1a-4c0fc99cfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da28d195-e94d-4b03-a0ee-178e82bd7a0f",
   "metadata": {},
   "source": [
    "First, we define some helper functions for adding slides, generating text and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7e2bcd-8213-4aa4-93ff-2b26f59dbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title_slide(presentation, title, authors):\n",
    "    \n",
    "    slide = presentation.slides.add_slide(presentation.slide_layouts[0])\n",
    "    slide.placeholders[0].text = title\n",
    "    slide.placeholders[1].text = authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1343f5a0-d711-41c6-9506-572dec68c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_slide(presentation, title, *args):\n",
    "    \"\"\"Add a new slide to a given presentation\n",
    "    \n",
    "    The presentation and the slide title are mandatory. \n",
    "    Addionally, text and images, or image urls can be passed as parameters.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import os\n",
    "\n",
    "    # we presume the second slide template (index=1) contains 1 object placeholders,  \n",
    "    # the third slide (index = 2) contains two object placeholders, and so on\n",
    "    num_objects = len(args)\n",
    "    slide = presentation.slides.add_slide(presentation.slide_layouts[num_objects])\n",
    "\n",
    "    # set title\n",
    "    title_shape = slide.placeholders[0] \n",
    "    title_shape.text = title\n",
    "\n",
    "    # add objects\n",
    "    for i, object in enumerate(args):\n",
    "        shape = list(slide.placeholders)[i + 1]\n",
    "\n",
    "        # in case it's a numpy array\n",
    "        if hasattr(object, \"dtype\") and hasattr(object, 'shape'):\n",
    "            aspect_ratio = image.shape[0] / image.shape[1]\n",
    "\n",
    "            image_path = 'temp.png'\n",
    "            im = Image.fromarray(image)\n",
    "            im.save(image_path)\n",
    "            \n",
    "            shape.text = ''\n",
    "            slide.shapes.add_picture(image_path, shape.left, shape.top, height=shape.height)\n",
    "\n",
    "            os.remove(image_path)\n",
    "        \n",
    "        # in case it's an image file\n",
    "        elif isinstance(object, str) and len(object) > 4 and object[-4:] in ['.png', '.jpg', '.tif'] and os.path.exists(object):\n",
    "            shape.text = ''\n",
    "            image_path = object\n",
    "            slide.shapes.add_picture(image_path, shape.left, shape.top, height=shape.height)\n",
    "\n",
    "        # otherwise is should be a string/text\n",
    "        else:\n",
    "            shape.text = object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce28efd0-355b-415a-bf24-f00ed0665ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dall_e_image(prompt, size_str=\"1024x1024\", model='dall-e-3'):\n",
    "    \"\"\"Generate an image using a given prompt\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    num_images=1\n",
    "    \n",
    "    client = OpenAI()\n",
    "    response = client.images.generate(\n",
    "      prompt=prompt,\n",
    "      n=num_images,\n",
    "      model=model,\n",
    "      size=size_str\n",
    "    )\n",
    "    return images_from_url_responses(response)\n",
    "\n",
    "\n",
    "def images_from_url_responses(response, input_shape = None):\n",
    "    \"\"\"Turns a list of OpenAI's URL responses into numpy images\"\"\"\n",
    "    from skimage.io import imread\n",
    "    from skimage import transform\n",
    "    import numpy as np\n",
    "    images = [imread(item.url) for item in response.data]\n",
    "\n",
    "    if input_shape is not None:\n",
    "        # make sure the output images have the same size and type as the input image\n",
    "        images = [transform.resize(image, input_shape, anti_aliasing=True, preserve_range=True).astype(image.dtype) for image in images]\n",
    "\n",
    "        if len(input_shape) == 2 and len(images[0].shape) == 3:\n",
    "            # we sent a grey-scale image and got RGB images back\n",
    "            images = [image[:,:,0] for image in images]\n",
    "\n",
    "    if len(images) == 1:\n",
    "        # If only one image was requested, return a single image\n",
    "        return images[0]\n",
    "    else:\n",
    "        # Otherwise return a list of images as numpy array / image stack\n",
    "        return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f0013c-4ab9-44e7-a572-ba568ad58847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_openai(user_prompt, system_prompt, model=\"gpt-4-0125-preview\"):\n",
    "    \"\"\"Send a text prompt to chatGPT and return its result as string\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    # assemble prompt\n",
    "    system_message = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    user_message = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "    # init client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # retrieve answer\n",
    "    response = client.chat.completions.create(\n",
    "        messages=system_message + user_message,\n",
    "        model=model\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad0d4521-b7ee-4d6d-ac92-7e5a85d314c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optical microscopy, also known as light microscopy, is a technique used to enlarge images of small objects using visible light. This type of microscopy is fundamental in biological research, material science, and various fields of study to observe details that are too small to be seen with the naked eye.\\n\\nThe basic component of an optical microscope is the lens system, which includes the objective lens and the eyepiece. The objective lens, positioned close to the specimen, creates an enlarged image. The eyepiece further magnifies this image for the observer. Modern microscopes often have multiple objective lenses, allowing for varying levels of magnification.\\n\\nProper illumination of the specimen is crucial for clear visualization. This is typically achieved through a light source beneath the sample stage, directed upwards, and sometimes, for more opaque objects, above the stage directed downwards. The condenser, another lens system below the stage, focuses the light onto the specimen, enhancing image contrast and clarity.\\n\\n\\nAdjusting the focus is a vital step in microscopy. Fine and coarse adjustment knobs are used to bring the specimen into sharp focus at different magnifications. Correct focusing involves moving the stage or the objective lens until the clearest possible image is obtained.\\n\\nSample preparation is another important step, particularly for biological specimens, which may require staining to enhance contrast or to highlight specific cellular components. Stains bind to specific structures within the cell or tissue, making them more visible under the microscope.\\n\\nFinally, the development of digital imaging techniques has significantly expanded the capabilities of optical microscopy. Cameras attached to microscopes can capture and store images for further analysis, allowing for detailed documentation and more sophisticated quantitative analysis of the observed specimens.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = prompt_openai(prompt + \"\\n\" + \"Separate important steps by two line breaks. Do not use separate headlines\", \"\")\n",
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304d3488-3526-46be-b331-49de2249e5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Enhancing small objects' visibility.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = prompt_openai('summarize the following into max 5 words:\\n' + story, \"\")    \n",
    "headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dd741-3bdf-48e2-804a-796d0d5028de",
   "metadata": {},
   "source": [
    "We now create a presentation file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09622df1-e4a6-4ea8-b502-017ab4c68d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation = Presentation('blank_template.pptx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daeaa34-6c2a-43fc-a2ac-6391c17bfdc9",
   "metadata": {},
   "source": [
    "... and add a first slide containing the headline and the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8ed4cd-6486-46d1-b5ff-bcadf59f4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_title_slide(presentation, headline, authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e4b10-b325-4b67-b8c9-34841be0f55c",
   "metadata": {},
   "source": [
    "We now split this story into parts to generate a slide for each part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3289070-cdd6-454b-9f68-e64fe23eb11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = story.split(\"\\n\\n\")\n",
    "len(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de8480b-09b5-4b43-ad79-d588641a9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in parts:\n",
    "    \n",
    "    image = draw_dall_e_image('draw an instructive image for this text section:\\n' + part)\n",
    "\n",
    "    headline = prompt_openai('summarize the following into max 5 words:\\n' + part, \"\")    \n",
    "    \n",
    "    add_slide(presentation, headline, part, image)\n",
    "\n",
    "    # save the PPTX file after adding a slide, just in case it crashes\n",
    "    presentation.save(pptx_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458e02c-4f1e-4b0c-a9d5-73fe260d349d",
   "metadata": {},
   "source": [
    "# Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185b040-3e76-42d2-b0ea-5d1b4f59ae56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
